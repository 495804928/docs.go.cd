### Challenges
When we set out to implement the feature we faced quiet a few challenges:

#### Deterministic vs Randomised Algorithm:
The algorithm had to be deterministic i.e. given a particular input, it should always produce the same output. This would keep the layout same when user would refresh VSM page. It would also keep the nodes at same position until there is change in configuration making it intuitive for human eye to search for a node.

#### Efficiency:
The algorithm had to run in polynomial time since it would be run frequently (every VSM page load). It should be fast enough that we could put a auto-refresh if we wanted to at some point of time.

#### Reusable:
The algorithm had to be scalable & reusable so that we could use it to display the whole of config as a Pipeline Dependency Graph (PDG).

#### Visualisation:
The algorithm should facilitate showing each dependency as separate line, i.e. not merge dependencies into one line so that we could show artifact being fetched from different pipeline separately. But it should minimise edge crossings so as to improve readability / visual appeal.

### Graph Representation & Instance Data population
To be able to implement the algorithm we needed to have Graph representation of whole upstream & downstream flow with respect to current pipeline. Building the graph for VSM is more tricky than it first seems like.

When you are building upstream graph you need to consider the build-cause that is stored in database for current pipeline & recursively traverse upstream build-causes to generate the whole upstream graph.

While for building downstream graph we need to see the config to see all pipelines that get triggered off of current pipeline & recurse downstream till we build the whole downstream graph.

Pipeline instances of upstream pipelines & SCM revisions are got during traversal of build cause, the pipeline instances of downstream pipelines are not directly available in any form. So we query for each pipeline instance we know (starting from current pipeline) - instances of downstream pipeline that ran off of current instance. Once we know the pipeline instances we populate stage information for pipeline instances.

### Algorithm
The Pipeline dependency graph is essentially a Directed Acyclic Graph (DAG). This would mean any algorithm for laying out DAGs would work.

We decided to implement Sugiyama Algorithm for this. The algorithm goes about laying out the graph in 4 steps:

1. Layer Assignment
2. Dummy Node Creation
3. Edge Cross Minimisation
4. Optimisation
